{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4424, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Dataset2neww.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_dataset' with the actual path to your dataset file\n",
    "#df = pd.read_excel('LastDataset1(neww).xlsx')\n",
    "#df.head()\n",
    "# Now you can work with your dataset stored in the variable 'df'\n",
    "X = df.drop(columns=['Course'])\n",
    "y = df['Course']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numerical_columns = X.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Create DataFrames for categorical and numerical columns\n",
    "X_categorical = X[categorical_columns]\n",
    "X_numerical = X[numerical_columns]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Perform label encoding only on columns with dtype object\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X_categorical.copy()\n",
    "for col in categorical_columns:\n",
    "    X_encoded[col] = X[col].astype(str)  # Ensure the column is of string dtype before label encoding\n",
    "    X_encoded[col] = label_encoder.fit_transform(X_encoded[col])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder for the target variable y\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "# Merge with original X containing int and float columns\n",
    "X_final = pd.concat([X_encoded, X.select_dtypes(include=['int', 'float'])], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.29265536723163843\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.420     0.853     0.563        34\n",
      "           2      0.727     0.250     0.372        32\n",
      "           3      0.000     0.000     0.000        50\n",
      "           4      0.240     0.154     0.188        39\n",
      "           5      0.111     0.044     0.063        68\n",
      "           6      0.000     0.000     0.000        33\n",
      "           7      0.000     0.000     0.000        39\n",
      "           8      0.000     0.000     0.000        64\n",
      "           9      0.274     0.227     0.248        75\n",
      "          10      0.000     0.000     0.000        53\n",
      "          11      0.246     0.926     0.389       163\n",
      "          12      0.000     0.000     0.000        23\n",
      "          13      0.000     0.000     0.000        40\n",
      "          14      0.000     0.000     0.000        78\n",
      "          15      0.000     0.000     0.000        41\n",
      "          16      0.652     0.938     0.769        48\n",
      "\n",
      "    accuracy                          0.293       885\n",
      "   macro avg      0.157     0.199     0.152       885\n",
      "weighted avg      0.166     0.293     0.183       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Initialize AdaBoost with the base estimator (DecisionTreeClassifier)\n",
    "ada_boost = AdaBoostClassifier(\n",
    " \n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model on the testing set\n",
    "y_pred_test = ada_boost.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test, digits=3)\n",
    "\n",
    "# Print the classification report for the testing set\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Testing Classification Report:\\n\", report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy (using manual calculation): 0.5242937853107345\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.620     0.912     0.738        34\n",
      "           2      0.839     0.812     0.825        32\n",
      "           3      0.492     0.620     0.549        50\n",
      "           4      0.448     0.333     0.382        39\n",
      "           5      0.528     0.412     0.463        68\n",
      "           6      0.333     0.424     0.373        33\n",
      "           7      0.381     0.205     0.267        39\n",
      "           8      0.366     0.406     0.385        64\n",
      "           9      0.413     0.507     0.455        75\n",
      "          10      0.405     0.283     0.333        53\n",
      "          11      0.623     0.822     0.709       163\n",
      "          12      0.833     0.217     0.345        23\n",
      "          13      0.417     0.375     0.395        40\n",
      "          14      0.500     0.385     0.435        78\n",
      "          15      0.241     0.171     0.200        41\n",
      "          16      0.878     0.896     0.887        48\n",
      "\n",
      "    accuracy                          0.524       885\n",
      "   macro avg      0.489     0.458     0.455       885\n",
      "weighted avg      0.515     0.524     0.507       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Initialize Gradient Boosting Classifier with specified parameters\n",
    "model = GradientBoostingClassifier(learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model on the testing set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy manually\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Accuracy (using manual calculation):\", accuracy_test)\n",
    "\n",
    "# Generate classification report\n",
    "report_test = classification_report(y_test, y_pred_test, digits=3)\n",
    "print(\"Testing Classification Report:\\n\", report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 3539, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -6.225689\n",
      "[LightGBM] [Info] Start training from score -2.973102\n",
      "[LightGBM] [Info] Start training from score -2.962113\n",
      "[LightGBM] [Info] Start training from score -3.096426\n",
      "[LightGBM] [Info] Start training from score -2.940491\n",
      "[LightGBM] [Info] Start training from score -2.576888\n",
      "[LightGBM] [Info] Start training from score -3.251619\n",
      "[LightGBM] [Info] Start training from score -3.546627\n",
      "[LightGBM] [Info] Start training from score -2.415857\n",
      "[LightGBM] [Info] Start training from score -2.536810\n",
      "[LightGBM] [Info] Start training from score -2.878295\n",
      "[LightGBM] [Info] Start training from score -1.769682\n",
      "[LightGBM] [Info] Start training from score -4.028465\n",
      "[LightGBM] [Info] Start training from score -2.742254\n",
      "[LightGBM] [Info] Start training from score -2.638210\n",
      "[LightGBM] [Info] Start training from score -3.154320\n",
      "[LightGBM] [Info] Start training from score -2.777972\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Testing Accuracy: 0.5491525423728814\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.738     0.912     0.816        34\n",
      "           2      0.793     0.719     0.754        32\n",
      "           3      0.689     0.620     0.653        50\n",
      "           4      0.450     0.462     0.456        39\n",
      "           5      0.467     0.515     0.490        68\n",
      "           6      0.513     0.606     0.556        33\n",
      "           7      0.267     0.103     0.148        39\n",
      "           8      0.400     0.500     0.444        64\n",
      "           9      0.446     0.547     0.491        75\n",
      "          10      0.359     0.264     0.304        53\n",
      "          11      0.706     0.883     0.785       163\n",
      "          12      0.750     0.130     0.222        23\n",
      "          13      0.326     0.350     0.337        40\n",
      "          14      0.439     0.321     0.370        78\n",
      "          15      0.310     0.220     0.257        41\n",
      "          16      0.824     0.875     0.848        48\n",
      "\n",
      "    accuracy                          0.549       885\n",
      "   macro avg      0.499     0.472     0.467       885\n",
      "weighted avg      0.533     0.549     0.529       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_final and y_encoded are your features and labels\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model on the testing set\n",
    "y_pred_test = lgbm.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test, digits=3)\n",
    "\n",
    "# Print the classification report for the testing set\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Testing Classification Report:\\n\", report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5378531073446328\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.640     0.941     0.762        34\n",
      "           2      0.862     0.781     0.820        32\n",
      "           3      0.500     0.600     0.545        50\n",
      "           4      0.500     0.333     0.400        39\n",
      "           5      0.493     0.485     0.489        68\n",
      "           6      0.459     0.515     0.486        33\n",
      "           7      0.409     0.231     0.295        39\n",
      "           8      0.419     0.484     0.449        64\n",
      "           9      0.433     0.520     0.473        75\n",
      "          10      0.344     0.208     0.259        53\n",
      "          11      0.680     0.847     0.754       163\n",
      "          12      0.500     0.087     0.148        23\n",
      "          13      0.234     0.275     0.253        40\n",
      "          14      0.477     0.397     0.434        78\n",
      "          15      0.357     0.244     0.290        41\n",
      "          16      0.863     0.917     0.889        48\n",
      "\n",
      "    accuracy                          0.538       885\n",
      "   macro avg      0.481     0.463     0.456       885\n",
      "weighted avg      0.521     0.538     0.518       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_final and y_encoded are your features and labels\n",
    "\n",
    "\n",
    "# Initialize CatBoost Classifier\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 to suppress output\n",
    "\n",
    "# Fit the model\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model on the testing set\n",
    "y_pred_test = catboost.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test, digits=3)\n",
    "\n",
    "# Print the classification report for the testing set\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Testing Classification Report:\\n\", report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5389830508474577\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.721     0.912     0.805        34\n",
      "           2      0.788     0.812     0.800        32\n",
      "           3      0.635     0.660     0.647        50\n",
      "           4      0.410     0.410     0.410        39\n",
      "           5      0.537     0.529     0.533        68\n",
      "           6      0.378     0.424     0.400        33\n",
      "           7      0.455     0.256     0.328        39\n",
      "           8      0.354     0.453     0.397        64\n",
      "           9      0.391     0.453     0.420        75\n",
      "          10      0.310     0.245     0.274        53\n",
      "          11      0.697     0.859     0.769       163\n",
      "          12      0.600     0.130     0.214        23\n",
      "          13      0.341     0.350     0.346        40\n",
      "          14      0.482     0.346     0.403        78\n",
      "          15      0.323     0.244     0.278        41\n",
      "          16      0.872     0.854     0.863        48\n",
      "\n",
      "    accuracy                          0.539       885\n",
      "   macro avg      0.488     0.467     0.464       885\n",
      "weighted avg      0.527     0.539     0.524       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model on the testing set\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test, digits=3)\n",
    "\n",
    "# Print the classification report for the testing set\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Testing Classification Report:\\n\", report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORUTAShap + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_dataset' with the actual path to your dataset file\n",
    "df = pd.read_excel('LastDataset1(neww).xlsx')\n",
    "\n",
    "# Now you can work with your dataset stored in the variable 'df'\n",
    "X = df[['Faculty_domain', 'Employed_Company_Name', 'Industry_sector', 'Employed_Company_district', 'Employed_Company_state', 'Employed_Company_Address', 'Main_job_scope',\n",
    " 'Main_job_Title', 'Work_in_the_same_field_of_learning', 'Faculty_Description', 'JS_Job_sub_sector', 'Employed_Company_lat', 'Faculty', 'Program_Description', 'Employed_Company_Postcode', 'Economic_sector', 'Current_Job_scope']]\n",
    "y = df['JS_Job_sector']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numerical_columns = X.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Create DataFrames for categorical and numerical columns\n",
    "X_categorical = X[categorical_columns]\n",
    "X_numerical = X[numerical_columns]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Perform label encoding only on columns with dtype object\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X_categorical.copy()\n",
    "for col in categorical_columns:\n",
    "    X_encoded[col] = X[col].astype(str)  # Ensure the column is of string dtype before label encoding\n",
    "    X_encoded[col] = label_encoder.fit_transform(X_encoded[col])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder for the target variable y\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "# Merge with original X containing int and float columns\n",
    "X_final = pd.concat([X_encoded, X.select_dtypes(include=['int', 'float'])], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
